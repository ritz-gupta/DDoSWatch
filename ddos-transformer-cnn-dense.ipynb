{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6425404,"sourceType":"datasetVersion","datasetId":3706998}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:53:41.521222Z","iopub.execute_input":"2024-04-02T19:53:41.521705Z","iopub.status.idle":"2024-04-02T19:53:42.877719Z","shell.execute_reply.started":"2024-04-02T19:53:41.521669Z","shell.execute_reply":"2024-04-02T19:53:42.876342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport os\n\ndef generate_datasets(directory):\n    train_path = '/kaggle/working/train.csv'\n    test_path = '/kaggle/working/test.csv'\n    i=0\n    for filename in os.listdir(directory):\n        if filename.endswith(\".csv\") and i<25:\n            filepath = os.path.join(directory, filename)\n            print(f\"Processing {filename}...\")\n            df = pd.read_csv(filepath)\n            filtered_df = df[df['label'].str.contains('ddos|benign', case=False, regex=True)]\n            filtered_df.loc[:, 'label'] = filtered_df['label'].str.contains(\"ddos\", case=False).astype('int8')\n            xs, ys = filtered_df.drop('label', axis=1), filtered_df['label']\n            x_train, x_test, y_train, y_test = train_test_split(xs, ys, test_size=0.3, random_state=42, stratify=ys)\n            train = pd.concat([x_train, y_train], axis=1)\n            test = pd.concat([x_test, y_test], axis=1)\n            train.to_csv(train_path, mode='a', header=not os.path.exists(train_path), index=False)\n            test.to_csv(test_path, mode='a', header=not os.path.exists(test_path), index=False)\n            del df, filtered_df, xs, ys, x_train, x_test, y_train, y_test, train, test\n            i+=1","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:53:44.891341Z","iopub.execute_input":"2024-04-02T19:53:44.891956Z","iopub.status.idle":"2024-04-02T19:53:46.396704Z","shell.execute_reply.started":"2024-04-02T19:53:44.89192Z","shell.execute_reply":"2024-04-02T19:53:46.39523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm /kaggle/working/test.csv\n# !rm /kaggle/working/train.csv","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:30:20.452084Z","iopub.execute_input":"2024-04-02T18:30:20.453109Z","iopub.status.idle":"2024-04-02T18:30:22.509932Z","shell.execute_reply.started":"2024-04-02T18:30:20.453063Z","shell.execute_reply":"2024-04-02T18:30:22.5086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_datasets(\"/kaggle/input/unb-cic-iot-dataset/wataiData/csv/CICIoT2023\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:53:56.201799Z","iopub.execute_input":"2024-04-02T19:53:56.202247Z","iopub.status.idle":"2024-04-02T19:56:31.805994Z","shell.execute_reply.started":"2024-04-02T19:53:56.202207Z","shell.execute_reply":"2024-04-02T19:56:31.804547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:56:34.798322Z","iopub.execute_input":"2024-04-02T19:56:34.798741Z","iopub.status.idle":"2024-04-02T19:56:38.606203Z","shell.execute_reply.started":"2024-04-02T19:56:34.79871Z","shell.execute_reply":"2024-04-02T19:56:38.604997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:56:40.752094Z","iopub.execute_input":"2024-04-02T19:56:40.75268Z","iopub.status.idle":"2024-04-02T19:56:40.761268Z","shell.execute_reply.started":"2024-04-02T19:56:40.752645Z","shell.execute_reply":"2024-04-02T19:56:40.75997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerLayer(nn.Module):\n    def __init__(self, num_heads, d_model, dff, max_len=1000, dropout_rate=0.1):\n        super(TransformerLayer, self).__init__()\n\n        self.multi_head_attn = nn.MultiheadAttention(d_model, num_heads)\n        self.feed_forward_net = nn.Sequential(\n            nn.Linear(d_model, dff),\n            nn.ReLU(),\n            nn.Linear(dff, d_model)\n        )\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n\n        self.dropout1 = nn.Dropout(dropout_rate)\n        self.dropout2 = nn.Dropout(dropout_rate)\n\n    def forward(self, x, mask=None):\n        #q, k, v\n        attn_output, _ = self.multi_head_attn(x, x, x, attn_mask=mask)\n        attn_output = self.dropout1(attn_output)\n        attn_output = self.norm1(x + attn_output)\n\n        ff_output = self.feed_forward_net(attn_output)\n        ff_output = self.dropout2(ff_output)\n        output = self.norm2(attn_output + ff_output)\n\n        return output\n\nclass CNNLayer(nn.Module):\n    def __init__(self, num_filters, kernel_size, d_model):\n        super(CNNLayer, self).__init__()\n        self.conv = nn.Conv1d(in_channels=d_model, out_channels=num_filters, kernel_size=kernel_size, padding='same')\n        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n\n    def forward(self, inputs):\n        conv = self.conv(inputs)\n        global_avg_pool = self.global_avg_pool(F.relu(conv))\n        return global_avg_pool\n\nclass DenseLayer(nn.Module):\n    def __init__(self, num_filters):\n        super(DenseLayer, self).__init__()\n        self.fc1 = nn.Linear(num_filters, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, 1)\n        \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = torch.sigmoid(self.fc3(x))\n        return x\n\nclass DDoSTCModel(nn.Module):\n    def __init__(self, num_heads, d_model, dff, num_filters, kernel_size, lr):\n        super(DDoSTCModel, self).__init__()\n        self.transformer = TransformerLayer(num_heads, d_model, dff)\n        self.cnn = CNNLayer(num_filters, kernel_size, d_model)\n        self.dense = DenseLayer(num_filters)\n        self.criterion = nn.BCELoss()\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n        \n    def forward(self, x):\n        transformer_out = self.transformer(x)\n        transformer_out = transformer_out.unsqueeze(2)\n        cnn_out = self.cnn(transformer_out)\n        cnn_squeeze = torch.squeeze(cnn_out, dim=2)\n        output = self.dense(cnn_squeeze)\n        return output\n    \n    def train(self, train_loader, epochs, device):\n        self.to(device)\n        \n        for epoch in range(epochs):\n            total_loss, total_acc = 0, 0\n            total_samples = 0\n            for data in train_loader:\n                inputs, labels = data\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                self.optimizer.zero_grad()\n                outputs = self(inputs)\n                loss = self.criterion(outputs, labels.unsqueeze(1))\n                loss.backward()\n                self.optimizer.step()\n                \n                total_loss += loss.item()\n                total_acc += (outputs.round() == labels.unsqueeze(1)).sum().item()\n                total_samples += labels.size(0)\n            \n            avg_loss = total_loss / len(train_loader)\n            acc = total_acc / total_samples\n            print(f\"Epoch {epoch + 1}/{epochs}: Loss: {avg_loss:.4f}, Accuracy: {acc*100:.4f}%\")\n        \n    def evaluate(self, test_loader, device):\n        self.to(device)\n        \n        all_predictions = []\n        total_acc = 0\n        total_samples = 0\n        with torch.no_grad():\n            for data in test_loader:\n                \n                inputs, labels = data\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                outputs = self(inputs)\n                \n                total_acc += (outputs.round() == labels.unsqueeze(1)).sum().item()\n                total_samples += labels.size(0)\n                \n                prediction = outputs.round()\n                all_predictions.append(prediction)\n            \n            acc = total_acc / total_samples\n\n        predictions = np.concatenate(all_predictions)\n        print(f\"Accuracy: {acc}\")\n        \n        return predictions","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T20:19:04.413961Z","iopub.execute_input":"2024-04-02T20:19:04.414435Z","iopub.status.idle":"2024-04-02T20:19:04.446552Z","shell.execute_reply.started":"2024-04-02T20:19:04.414387Z","shell.execute_reply":"2024-04-02T20:19:04.44497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_heads = 2\nd_model = 46\ndff = 128\nnum_filters = 64\nkernel_size = 3\nlr = 3e-4","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:57:01.475536Z","iopub.execute_input":"2024-04-02T19:57:01.475954Z","iopub.status.idle":"2024-04-02T19:57:01.482238Z","shell.execute_reply.started":"2024-04-02T19:57:01.475922Z","shell.execute_reply":"2024-04-02T19:57:01.480812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DDoSTCModel(num_heads, d_model, dff, num_filters, kernel_size, lr)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:19:06.560064Z","iopub.execute_input":"2024-04-02T20:19:06.560582Z","iopub.status.idle":"2024-04-02T20:19:06.571716Z","shell.execute_reply.started":"2024-04-02T20:19:06.560543Z","shell.execute_reply":"2024-04-02T20:19:06.570097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data.dataset import random_split\n\ntrain_df = pd.read_csv('/kaggle/working/train.csv')\ny_train = torch.tensor(train_df['label'].values, dtype=torch.float32)\nX_train = torch.tensor(train_df.drop(columns=['label'], axis=1).values, dtype=torch.float32)\ntrain_dataset = TensorDataset(X_train, y_train)\n\n\ntrain_size = int(0.1 * len(train_dataset))\ntest_size = len(train_dataset) - train_size \n\ntrain_dataset_small, test_dataset = random_split(train_dataset, [train_size, test_size])\ntrain_loader = DataLoader(train_dataset_small, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:57:10.481997Z","iopub.execute_input":"2024-04-02T19:57:10.482589Z","iopub.status.idle":"2024-04-02T19:57:21.50527Z","shell.execute_reply.started":"2024-04-02T19:57:10.482557Z","shell.execute_reply":"2024-04-02T19:57:21.503956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=10\nmodel.train(train_loader, epochs, device)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:19:09.899044Z","iopub.execute_input":"2024-04-02T20:19:09.899584Z","iopub.status.idle":"2024-04-02T20:20:48.578641Z","shell.execute_reply.started":"2024-04-02T20:19:09.899536Z","shell.execute_reply":"2024-04-02T20:20:48.577016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/working/test.csv')\ny_test = torch.tensor(test_df['label'].values, dtype=torch.float32)\nX_test = torch.tensor(test_df.drop(columns=['label'], axis=1).values, dtype=torch.float32)\ntest_dataset = TensorDataset(X_test, y_test)\n\ntest_size = int(len(test_dataset)) \n\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:13:42.709115Z","iopub.execute_input":"2024-04-02T20:13:42.710267Z","iopub.status.idle":"2024-04-02T20:13:47.32568Z","shell.execute_reply.started":"2024-04-02T20:13:42.710224Z","shell.execute_reply":"2024-04-02T20:13:47.32426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:13:50.203828Z","iopub.execute_input":"2024-04-02T20:13:50.204252Z","iopub.status.idle":"2024-04-02T20:13:50.210916Z","shell.execute_reply.started":"2024-04-02T20:13:50.204219Z","shell.execute_reply":"2024-04-02T20:13:50.209084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.evaluate(test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:20:54.284619Z","iopub.execute_input":"2024-04-02T20:20:54.285639Z","iopub.status.idle":"2024-04-02T20:21:21.577834Z","shell.execute_reply.started":"2024-04-02T20:20:54.285586Z","shell.execute_reply":"2024-04-02T20:21:21.57649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# Assuming you have your model predictions and true labels\n\n# Compute ROC curve\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC)')\nplt.legend(loc=\"lower right\")\nplt.text(0.6, 0.2, 'AUC = %0.2f' % roc_auc, ha='center', fontsize=12)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T20:24:08.025214Z","iopub.execute_input":"2024-04-02T20:24:08.02688Z","iopub.status.idle":"2024-04-02T20:24:08.436508Z","shell.execute_reply.started":"2024-04-02T20:24:08.02684Z","shell.execute_reply":"2024-04-02T20:24:08.435501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''TESTING'''\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\n# num_data = 10000\n# input_dim = 46  # Assuming your input data has 10 features\n# X_test = torch.randn(num_data, input_dim)  # Random values between -1 and 1\n# t = torch.tensor(X_test, dtype=torch.float32)\nX_test_df = test_df.drop(columns=['label'], axis=1).values\nY_test_df = test_df['label'].values\nX_test = torch.tensor(X_test_df, dtype=torch.float32)\nt = X_test.clone().detach()\ntest_dataset = TensorDataset(t)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\nmodel.eval()\nall_predictions = []\nwith torch.no_grad():  # No need to compute gradients during inference\n    for batch_data in test_loader:\n        # Forward pass\n        batch_outputs = model(batch_data[0])\n        batch_predictions = (batch_outputs > 0.5).squeeze().numpy()\n        all_predictions.append(batch_predictions)\n\n# Concatenate predictions from all batches\npredictions = np.concatenate(all_predictions)\n\n# Print predictions\n# print(\"Predictions:\", predictions)\n\ncorrect_predictions = np.sum(predictions == Y_test_df)\ntotal_samples = len(Y_test_df)\naccuracy = correct_predictions / total_samples\n\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T18:25:46.838472Z","iopub.status.idle":"2024-04-02T18:25:46.838855Z","shell.execute_reply.started":"2024-04-02T18:25:46.838634Z","shell.execute_reply":"2024-04-02T18:25:46.838647Z"},"trusted":true},"execution_count":null,"outputs":[]}]}